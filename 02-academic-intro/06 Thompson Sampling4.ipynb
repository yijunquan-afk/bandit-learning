{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Multi-Armed Bandits——05 Thompson Sampling[3]\n",
    "\n",
    "## 参考资料\n",
    "\n",
    "1. Russo D J, Van Roy B, Kazerouni A, et al. A tutorial on thompson sampling[J]. Foundations and Trends® in Machine Learning, 2018, 11(1): 1-96.\n",
    "\n",
    "2. [ts_tutorial](https://github.com/iosband/ts_tutorial)\n",
    "\n",
    "项目代码地址: [https://github.com/yijunquan-afk/bandit-learning.git](https://github.com/yijunquan-afk/bandit-learning.git)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、新闻文章推荐\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题描述"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们考虑一个在线新闻文章推荐问题，在这个问题中，一个网站需要学习向其用户推荐**个性化**（personalized）和**上下文敏感**（contextsensitive）的新闻文章。该网站与一连串的用户进行互动，以 $t/{1,2,/ldots/}$ 为索引。在每个回合 $t$ 中，它观察到一个第 $t$ 个用户相关的特征向量 $z_{t} \\in \\mathbb{R}^d$，从 $k$ 篇文章组成的集合 $\\mathcal{X}=\\{1,\\ldots, k\\}$ 中选择一篇新闻文章 $x_t$ 进行展示，然后观察表示用户是否喜欢这篇文章的二项奖励 $r_{t}$。\n",
    "\n",
    "例如，用户的特征向量可以编码以下信息。\n",
    "\n",
    "+ 访问用户的近期活动，如用户最近阅读的新闻文章。\n",
    "\n",
    "+ 访问用户的个人统计信息，如用户的性别和年龄。\n",
    "\n",
    "+ 访问用户的背景信息，如用户的位置和星期几。\n",
    "\n",
    "根据[An Empirical Evaluation of Thompson Sampling](https://proceedings.neurips.cc/paper/2011/hash/e53a0a2978c28872a4505bdb51db06dc-Abstract.html)这篇论文的第五节，我们可以通过一个Logit模型来模拟具有 $z_t$ 特征的用户喜欢某篇文章 $x_t$ 的概率。具体来说，$\\mathcal{X}$中的每篇文章 $x_t$ 都与$d$维参数向量$\\theta_x \\in \\mathbb{R}^d$ 有关。在 $x_t$、$\\theta_{x_t}$ 和 $z_{t}$ 的条件下，用户给出正面评价的概率为 $g(z_{t}^T \\theta_{x_t})$，其中 $g$ 是logistic函数，由 $g(a) = 1/(1+e^{-a})$ 给出。这个问题的每阶段悔值被定义为\n",
    "$$\n",
    "\\mathrm{regret}_t \\left( \\theta_1, \\ldots, \\theta_K \\right)=\\max_{x \\in \\mathcal{X}} g(z_{t}^T \\theta_{x}) - g(z_{t}^T \\theta_{x_t}) \\quad \\forall t=1,2,\\ldots\n",
    "$$\n",
    "并衡量推荐的文章 $x_t$ 与根据用户的特征可能做出的最佳推荐之间的质量差距。这个模型允许在不同的用户之间进行归纳，使网站能够学习向不同用户推荐某篇新闻文章的经验，预测具有给定特征的用户 $z_t$ 是否会喜欢该文章。\n",
    "\n",
    "这个问题不适合于有效的精确贝叶斯推断。因此，我们应用了两种近似的Thompson抽样方法：一种是从后验的Laplace近似中抽样，另一种使用Langevin Monte Carlo来生成近似的后验样本。 为了提供一个基线，我们还应用了$\\epsilon$-greedy算法，并在 $epsilon$ 的各个值中寻找最佳表现。\n",
    "\n",
    "我们提出了一个简化的的模拟结果，其中有 $K=|\\mathcal{X}|=3$ 篇新闻文章、特征维度为 $d=7$ 。在每个时间 $t\\in\\{1,2,\\cdots\\}$，特征向量 $z_{t}$ 的第一个分量为常数 $1$ ，其他每个分量都是从成功概率为 $1/6$ 的伯努利分布中独立抽取。例如，$z_{t}$ 的每个分量都可以表示存在某个特定的特征，比如用户是否是女性或从美国境内访问网站，其中 $\\theta_{x}$ 的相应分量将反映具有该特征的用户是否比其他用户更喜欢文章 $x$ ，而 $\\theta_{x}$ 的第一个分量反映文章的总体受欢迎程度。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图展示了应用 Laplace 和 Langevin Monte Carlo 的汤普森采样以及贪婪和$\\epsilon$-greedy算法的结果。上图是由2000个随机问题实例的平均数产生的。 在每个实例中，$\\theta_x$ 都是从 $N(0, I)$ 中独立抽取的，其中 $I$ 是 $7/times 7$ 单位矩阵。根据我们的模拟，$\\epsilon$-greedy算法在 $\\epsilon=0.01$ 时产生的悔值最低。 即使有了这个优化值，它的悔值也大大超过了汤普森采样。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码编写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "[[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.ones((3,3)))\n",
    "print(np.diag([1,2,3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
